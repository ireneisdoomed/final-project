{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset BG + Gestos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = pd.read_csv(\"../data/processed/background.csv\")\n",
    "foreground = pd.read_csv(\"../data/processed/newTrain.csv\")\n",
    "foreground_test = pd.read_csv(\"../data/processed/newTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1      2     3     4      5     6     7     8     9  ...   775  \\\n",
       "0  73.0  91.0  102.0  97.0  81.0  101.0  80.0  75.0  74.0  64.0  ...  92.0   \n",
       "1  79.0  85.0  101.0  94.0  89.0   91.0  77.0  77.0  70.0  67.0  ...  97.0   \n",
       "2  68.0  86.0  102.0  89.0  87.0   88.0  71.0  75.0  70.0  66.0  ...  91.0   \n",
       "3  66.0  95.0   98.0  86.0  88.0   81.0  70.0  75.0  68.0  56.0  ...  96.0   \n",
       "4  66.0  95.0   98.0  86.0  88.0   81.0  70.0  75.0  68.0  56.0  ...  96.0   \n",
       "\n",
       "    776    777    778    779    780    781    782    783  label  \n",
       "0  88.0   90.0  181.0  213.0  207.0  171.0  170.0   97.0  other  \n",
       "1  82.0   93.0  201.0  207.0  197.0  152.0  170.0  100.0  other  \n",
       "2  82.0  121.0  218.0  198.0  192.0  159.0  168.0  101.0  other  \n",
       "3  84.0  143.0  206.0  194.0  194.0  163.0  163.0   93.0  other  \n",
       "4  84.0  143.0  206.0  194.0  194.0  163.0  163.0   93.0  other  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>197</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>182</td>\n",
       "      <td>213</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>142</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>198</td>\n",
       "      <td>200</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>197</td>\n",
       "      <td>198</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "      <td>234</td>\n",
       "      <td>237</td>\n",
       "      <td>238</td>\n",
       "      <td>241</td>\n",
       "      <td>243</td>\n",
       "      <td>244</td>\n",
       "      <td>248</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>66</td>\n",
       "      <td>199</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>147</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>154</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>167</td>\n",
       "      <td>133</td>\n",
       "      <td>135</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0     A     197     195     196     195     197     196     195     196   \n",
       "1     A     142     144     144     146     147     149     150     151   \n",
       "2     A     198     200     201     200     199     198     198     197   \n",
       "3     A     231     232     234     237     238     241     243     244   \n",
       "4     A     147     149     150     152     153     153     152     153   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     196  ...        84        65       182       213       211       212   \n",
       "1     153  ...       178       179       179       180       181       182   \n",
       "2     198  ...       100        99        99        98        99        98   \n",
       "3     248  ...        90        66       199       255       255       255   \n",
       "4     154  ...       174       165       166       165       166       169   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       212       213       213       213  \n",
       "1       182       182       183       183  \n",
       "2       100       100       101       100  \n",
       "3       255       255       255       255  \n",
       "4       167       133       135       140  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(background.head())\n",
    "display(foreground.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_background = background.drop(\"label\", axis=1)\n",
    "X_foreground = foreground.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_background.columns = X_foreground.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New DFs\n",
    "\n",
    "new_fg = X_foreground\n",
    "new_fg[\"label\"] = foreground[\"label\"]\n",
    "\n",
    "new_bg = X_background\n",
    "new_bg[\"label\"] = background[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>179.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0   197.0   195.0   196.0   195.0   197.0   196.0   195.0   196.0   196.0   \n",
       "1   142.0   144.0   144.0   146.0   147.0   149.0   150.0   151.0   153.0   \n",
       "2   198.0   200.0   201.0   200.0   199.0   198.0   198.0   197.0   198.0   \n",
       "3   231.0   232.0   234.0   237.0   238.0   241.0   243.0   244.0   248.0   \n",
       "4   147.0   149.0   150.0   152.0   153.0   153.0   152.0   153.0   154.0   \n",
       "\n",
       "   pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
       "0    196.0  ...      65.0     182.0     213.0     211.0     212.0     212.0   \n",
       "1    154.0  ...     179.0     179.0     180.0     181.0     182.0     182.0   \n",
       "2    199.0  ...      99.0      99.0      98.0      99.0      98.0     100.0   \n",
       "3    249.0  ...      66.0     199.0     255.0     255.0     255.0     255.0   \n",
       "4    154.0  ...     165.0     166.0     165.0     166.0     169.0     167.0   \n",
       "\n",
       "   pixel782  pixel783  pixel784  label  \n",
       "0     213.0     213.0     213.0      A  \n",
       "1     182.0     183.0     183.0      A  \n",
       "2     100.0     101.0     100.0      A  \n",
       "3     255.0     255.0     255.0      A  \n",
       "4     133.0     135.0     140.0      A  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([new_fg, new_bg, foreground_test])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14171, 785)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77254902, 0.76470588, 0.76862745, ..., 0.83529412, 0.83529412,\n",
       "        0.83529412],\n",
       "       [0.55686275, 0.56470588, 0.56470588, ..., 0.71372549, 0.71764706,\n",
       "        0.71764706],\n",
       "       [0.77647059, 0.78431373, 0.78823529, ..., 0.39215686, 0.39607843,\n",
       "        0.39215686],\n",
       "       ...,\n",
       "       [0.67058824, 0.67058824, 0.67058824, ..., 0.25882353, 0.23529412,\n",
       "        0.23137255],\n",
       "       [0.69803922, 0.69803922, 0.69803922, ..., 0.18823529, 0.16078431,\n",
       "        0.15294118],\n",
       "       [0.68627451, 0.69019608, 0.69019608, ..., 0.1254902 , 0.09019608,\n",
       "        0.08627451]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"../data/processed/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other    5509\n",
       "A        1457\n",
       "F        1451\n",
       "Y        1450\n",
       "B        1442\n",
       "T        1434\n",
       "V        1428\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/data.csv\")\n",
    "\n",
    "X = data.drop(\"label\", axis=1)\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (11336, 28, 28, 1)\n",
      "11336 train samples\n",
      "2835 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 7\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "# DF to np array. Keras needs one-hot encoded y for multilabel classification.\n",
    "\n",
    "X_train_vector = X_train.values.reshape((X_train.shape[0], img_rows, img_cols))\n",
    "X_test_vector = X_test.values.reshape((X_test.shape[0], img_rows, img_cols))\n",
    "\n",
    "\n",
    "# Ask keras which format to use depending on used backend and arrange data as expected\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train_vector = X_train_vector.reshape(X_train_vector.shape[0], 1, img_rows, img_cols)\n",
    "    X_test_vector = X_test_vector.reshape(X_test_vector.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train_vector = X_train_vector.reshape(X_train_vector.shape[0], img_rows, img_cols, 1)\n",
    "    X_test_vector = X_test_vector.reshape(X_test_vector.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Incoming data is in uint8. Cast the input data images to be floats in range [0.0-1.0]  \n",
    "X_train_vector = X_train_vector.astype('float32') / 255\n",
    "X_test_vector = X_test_vector.astype('float32') / 255\n",
    "\n",
    "print('x_train shape:', X_train_vector.shape)\n",
    "print(X_train_vector.shape[0], 'train samples')\n",
    "print(X_test_vector.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to class matrices\n",
    "y_train_vector = y_train.values\n",
    "y_test_vector = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the neural network proposed architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11336 samples, validate on 2835 samples\n",
      "Epoch 1/30\n",
      "11336/11336 [==============================] - 28s 2ms/step - loss: 0.3294 - accuracy: 0.8927 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "11336/11336 [==============================] - 28s 2ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 1.7407e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "11336/11336 [==============================] - 24s 2ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 5.9647e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "11336/11336 [==============================] - 24s 2ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 2.6983e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "11336/11336 [==============================] - 25s 2ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 7.2502e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "11336/11336 [==============================] - 24s 2ms/step - loss: 9.4945e-04 - accuracy: 0.9997 - val_loss: 3.3817e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "11336/11336 [==============================] - 23s 2ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.7690e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "11336/11336 [==============================] - 23s 2ms/step - loss: 6.3219e-04 - accuracy: 0.9998 - val_loss: 9.8811e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "11336/11336 [==============================] - 23s 2ms/step - loss: 6.0151e-04 - accuracy: 0.9998 - val_loss: 6.3622e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "11336/11336 [==============================] - 23s 2ms/step - loss: 1.8573e-04 - accuracy: 1.0000 - val_loss: 3.5551e-07 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "11336/11336 [==============================] - 24s 2ms/step - loss: 3.3590e-04 - accuracy: 1.0000 - val_loss: 7.7776e-07 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "11336/11336 [==============================] - 28s 2ms/step - loss: 3.1709e-04 - accuracy: 0.9999 - val_loss: 3.5147e-07 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "11336/11336 [==============================] - 28s 2ms/step - loss: 2.0319e-04 - accuracy: 1.0000 - val_loss: 1.0066e-07 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 1.3809e-04 - accuracy: 1.0000 - val_loss: 3.7466e-08 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "11336/11336 [==============================] - 29s 3ms/step - loss: 4.1541e-04 - accuracy: 0.9999 - val_loss: 4.4277e-08 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "11336/11336 [==============================] - 31s 3ms/step - loss: 1.3760e-04 - accuracy: 1.0000 - val_loss: 4.6674e-08 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "11336/11336 [==============================] - 25s 2ms/step - loss: 6.6074e-04 - accuracy: 0.9998 - val_loss: 2.0986e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "11336/11336 [==============================] - 25s 2ms/step - loss: 2.0101e-04 - accuracy: 0.9999 - val_loss: 2.9981e-08 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "11336/11336 [==============================] - 23s 2ms/step - loss: 4.1848e-04 - accuracy: 0.9999 - val_loss: 3.2672e-08 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "11336/11336 [==============================] - 26s 2ms/step - loss: 1.7892e-04 - accuracy: 0.9999 - val_loss: 8.1910e-08 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 5.5031e-04 - accuracy: 0.9999 - val_loss: 5.7859e-08 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 2.7305e-04 - accuracy: 0.9999 - val_loss: 2.1235e-08 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 2.6344e-04 - accuracy: 0.9999 - val_loss: 9.6713e-09 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 1.9269e-04 - accuracy: 0.9999 - val_loss: 8.3209e-07 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 1.9885e-04 - accuracy: 0.9999 - val_loss: 1.8796e-08 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 9.8428e-05 - accuracy: 1.0000 - val_loss: 5.0038e-09 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 9.9021e-05 - accuracy: 1.0000 - val_loss: 4.1208e-09 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 8.7564e-05 - accuracy: 1.0000 - val_loss: 8.2837e-09 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 8.3660e-05 - accuracy: 1.0000 - val_loss: 4.8777e-09 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "11336/11336 [==============================] - 30s 3ms/step - loss: 1.2865e-04 - accuracy: 1.0000 - val_loss: 6.8961e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe480b1fa10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the NN\n",
    "batch_size = 20\n",
    "epochs = 30\n",
    "\n",
    "model.fit(X_train_vector, y_train_vector,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.896052366260763e-09\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with test data\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-acf587e557fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Gráfico función pérdida + accuracy\n",
    "\n",
    "\"\"\"import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo modelo mucho más grande por la noche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the neural network proposed architecture\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11336 samples, validate on 2835 samples\n",
      "Epoch 1/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1489 - accuracy: 0.6255 - val_loss: 0.2032 - val_accuracy: 0.9520\n",
      "Epoch 2/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.1426 - accuracy: 0.9649 - val_loss: 0.0198 - val_accuracy: 0.9982\n",
      "Epoch 3/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0352 - accuracy: 0.9923 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 4/500\n",
      "11336/11336 [==============================] - 17s 2ms/step - loss: 0.0173 - accuracy: 0.9967 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 5/500\n",
      "11336/11336 [==============================] - 15s 1ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 4.4424e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 3.6431e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 2.2418e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 1.5387e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 5.2690e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 5.8502e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 5.4218e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 3.7295e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.9172e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 6.2014e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 2.0551e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.5084e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.0741e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.7311e-04 - accuracy: 1.0000 - val_loss: 4.5243e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.3493e-04 - accuracy: 0.9999 - val_loss: 2.5470e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.8949e-04 - accuracy: 0.9997 - val_loss: 2.9873e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.7813e-04 - accuracy: 0.9998 - val_loss: 4.5831e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.5153e-04 - accuracy: 0.9999 - val_loss: 6.3657e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.2053e-04 - accuracy: 0.9998 - val_loss: 3.0844e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/500\n",
      "11336/11336 [==============================] - 17s 2ms/step - loss: 6.5812e-04 - accuracy: 0.9999 - val_loss: 2.0447e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7887e-04 - accuracy: 1.0000 - val_loss: 1.2674e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.4574e-04 - accuracy: 1.0000 - val_loss: 6.3778e-07 - val_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.9384e-04 - accuracy: 0.9997 - val_loss: 1.3714e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8569e-04 - accuracy: 0.9999 - val_loss: 3.1762e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.7564e-04 - accuracy: 0.9998 - val_loss: 2.1961e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8899e-04 - accuracy: 1.0000 - val_loss: 1.2175e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4754e-04 - accuracy: 0.9999 - val_loss: 4.6402e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9793e-04 - accuracy: 1.0000 - val_loss: 7.4626e-07 - val_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.6528e-04 - accuracy: 0.9999 - val_loss: 4.8458e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.9528e-04 - accuracy: 0.9999 - val_loss: 9.2833e-07 - val_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8555e-04 - accuracy: 1.0000 - val_loss: 5.7681e-07 - val_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1069e-04 - accuracy: 1.0000 - val_loss: 6.1127e-07 - val_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4489e-04 - accuracy: 1.0000 - val_loss: 2.0271e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7772e-04 - accuracy: 1.0000 - val_loss: 2.6125e-07 - val_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4837e-04 - accuracy: 0.9999 - val_loss: 6.6116e-07 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7490e-04 - accuracy: 1.0000 - val_loss: 3.9356e-07 - val_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.4095e-04 - accuracy: 0.9999 - val_loss: 2.0978e-07 - val_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4827e-04 - accuracy: 0.9998 - val_loss: 1.6474e-07 - val_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.4269e-04 - accuracy: 0.9998 - val_loss: 2.4291e-07 - val_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4371e-04 - accuracy: 1.0000 - val_loss: 1.2573e-07 - val_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6971e-04 - accuracy: 0.9999 - val_loss: 2.9240e-07 - val_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7449e-04 - accuracy: 1.0000 - val_loss: 2.0427e-07 - val_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.3972e-04 - accuracy: 1.0000 - val_loss: 3.9365e-07 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.5589e-04 - accuracy: 0.9999 - val_loss: 2.7772e-07 - val_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2199e-04 - accuracy: 1.0000 - val_loss: 1.3422e-07 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1216e-04 - accuracy: 1.0000 - val_loss: 1.0403e-07 - val_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0001e-04 - accuracy: 1.0000 - val_loss: 5.3360e-08 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1011e-04 - accuracy: 1.0000 - val_loss: 1.1723e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.3891e-05 - accuracy: 1.0000 - val_loss: 2.2234e-07 - val_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0878e-04 - accuracy: 1.0000 - val_loss: 3.0838e-07 - val_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0871e-04 - accuracy: 1.0000 - val_loss: 6.7527e-08 - val_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2029e-04 - accuracy: 1.0000 - val_loss: 4.7598e-08 - val_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1331e-04 - accuracy: 1.0000 - val_loss: 2.4516e-07 - val_accuracy: 1.0000\n",
      "Epoch 58/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7181e-04 - accuracy: 1.0000 - val_loss: 5.4495e-08 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1260e-04 - accuracy: 0.9999 - val_loss: 4.3738e-07 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.2287e-04 - accuracy: 0.9999 - val_loss: 5.3192e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.3991e-05 - accuracy: 1.0000 - val_loss: 1.2172e-07 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.4513e-05 - accuracy: 1.0000 - val_loss: 3.1494e-08 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.9221e-05 - accuracy: 1.0000 - val_loss: 2.0033e-07 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6985e-05 - accuracy: 1.0000 - val_loss: 3.1579e-08 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.5468e-05 - accuracy: 1.0000 - val_loss: 5.2517e-08 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5598e-04 - accuracy: 0.9999 - val_loss: 1.5738e-07 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.9629e-05 - accuracy: 1.0000 - val_loss: 1.1197e-07 - val_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.0797e-05 - accuracy: 1.0000 - val_loss: 2.5902e-08 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2080e-04 - accuracy: 0.9999 - val_loss: 1.9174e-08 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.9326e-05 - accuracy: 1.0000 - val_loss: 1.5493e-07 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.6805e-05 - accuracy: 1.0000 - val_loss: 3.2041e-08 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3005e-04 - accuracy: 1.0000 - val_loss: 9.5070e-08 - val_accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2368e-04 - accuracy: 1.0000 - val_loss: 1.7033e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6527e-04 - accuracy: 0.9999 - val_loss: 6.1979e-08 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.0362e-05 - accuracy: 1.0000 - val_loss: 2.7458e-08 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.8328e-04 - accuracy: 0.9996 - val_loss: 4.1713e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.4439e-05 - accuracy: 1.0000 - val_loss: 2.4220e-08 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5579e-04 - accuracy: 1.0000 - val_loss: 1.0487e-07 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1741e-04 - accuracy: 1.0000 - val_loss: 4.7599e-08 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3830e-04 - accuracy: 0.9999 - val_loss: 4.1881e-08 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1744e-04 - accuracy: 0.9999 - val_loss: 6.0971e-08 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.3097e-05 - accuracy: 1.0000 - val_loss: 1.3565e-07 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6295e-05 - accuracy: 1.0000 - val_loss: 3.1579e-08 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.8242e-05 - accuracy: 1.0000 - val_loss: 2.3295e-08 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5358e-04 - accuracy: 1.0000 - val_loss: 3.6540e-08 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.1627e-05 - accuracy: 1.0000 - val_loss: 2.1950e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.0976e-04 - accuracy: 0.9999 - val_loss: 2.7626e-08 - val_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.5719e-05 - accuracy: 1.0000 - val_loss: 2.4514e-08 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.0130e-05 - accuracy: 1.0000 - val_loss: 3.2629e-08 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.4204e-05 - accuracy: 1.0000 - val_loss: 1.2825e-08 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.2969e-05 - accuracy: 1.0000 - val_loss: 1.3372e-08 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7176e-05 - accuracy: 1.0000 - val_loss: 8.1155e-09 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7030e-04 - accuracy: 0.9999 - val_loss: 2.7037e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.7724e-05 - accuracy: 1.0000 - val_loss: 1.6315e-08 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6620e-05 - accuracy: 1.0000 - val_loss: 2.0478e-08 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.8754e-05 - accuracy: 1.0000 - val_loss: 1.5474e-08 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.5403e-05 - accuracy: 1.0000 - val_loss: 6.4081e-08 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6210e-05 - accuracy: 1.0000 - val_loss: 1.5810e-08 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.0589e-05 - accuracy: 1.0000 - val_loss: 1.1017e-08 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9742e-04 - accuracy: 0.9999 - val_loss: 1.6946e-08 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7430e-05 - accuracy: 1.0000 - val_loss: 2.3379e-08 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8129e-05 - accuracy: 1.0000 - val_loss: 1.0344e-08 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0553e-04 - accuracy: 0.9999 - val_loss: 1.8544e-08 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.4799e-05 - accuracy: 1.0000 - val_loss: 3.0275e-08 - val_accuracy: 1.0000\n",
      "Epoch 105/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.3462e-05 - accuracy: 1.0000 - val_loss: 1.8922e-08 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.4051e-04 - accuracy: 0.9999 - val_loss: 5.5923e-08 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.4096e-05 - accuracy: 1.0000 - val_loss: 2.4851e-08 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.4432e-05 - accuracy: 1.0000 - val_loss: 1.6567e-08 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.7684e-05 - accuracy: 1.0000 - val_loss: 1.8459e-08 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.6178e-05 - accuracy: 1.0000 - val_loss: 6.2233e-09 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2833e-04 - accuracy: 0.9999 - val_loss: 9.2087e-09 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8180e-04 - accuracy: 0.9999 - val_loss: 1.9207e-07 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.1642e-05 - accuracy: 1.0000 - val_loss: 2.5608e-08 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5418e-04 - accuracy: 1.0000 - val_loss: 3.6667e-08 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.9976e-04 - accuracy: 0.9997 - val_loss: 8.6999e-08 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.8599e-05 - accuracy: 1.0000 - val_loss: 7.0305e-08 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6531e-05 - accuracy: 1.0000 - val_loss: 3.0528e-08 - val_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.0672e-05 - accuracy: 1.0000 - val_loss: 1.7324e-08 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.3311e-05 - accuracy: 1.0000 - val_loss: 1.1101e-08 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.7454e-05 - accuracy: 1.0000 - val_loss: 1.2026e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.7542e-05 - accuracy: 1.0000 - val_loss: 8.4098e-09 - val_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.7336e-05 - accuracy: 1.0000 - val_loss: 7.9473e-09 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.9772e-05 - accuracy: 1.0000 - val_loss: 7.4006e-09 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1556e-05 - accuracy: 1.0000 - val_loss: 4.4993e-09 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6910e-05 - accuracy: 1.0000 - val_loss: 2.7332e-09 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.5989e-05 - accuracy: 1.0000 - val_loss: 3.4060e-09 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.2050e-05 - accuracy: 0.9999 - val_loss: 9.6713e-09 - val_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7479e-04 - accuracy: 0.9998 - val_loss: 1.4872e-07 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.5425e-05 - accuracy: 1.0000 - val_loss: 1.0891e-08 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8696e-05 - accuracy: 1.0000 - val_loss: 4.9197e-09 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.1381e-05 - accuracy: 1.0000 - val_loss: 1.7576e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.5524e-04 - accuracy: 0.9999 - val_loss: 1.3918e-08 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4876e-05 - accuracy: 1.0000 - val_loss: 4.6254e-09 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.6319e-05 - accuracy: 1.0000 - val_loss: 1.5684e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6522e-05 - accuracy: 1.0000 - val_loss: 3.1537e-09 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8142e-04 - accuracy: 0.9999 - val_loss: 1.4171e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.1123e-05 - accuracy: 1.0000 - val_loss: 4.4950e-08 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.5745e-05 - accuracy: 1.0000 - val_loss: 9.9236e-09 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.5671e-05 - accuracy: 1.0000 - val_loss: 4.7515e-09 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2784e-05 - accuracy: 1.0000 - val_loss: 3.2378e-09 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.5732e-05 - accuracy: 1.0000 - val_loss: 5.1720e-09 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8111e-05 - accuracy: 1.0000 - val_loss: 3.9947e-09 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.5610e-05 - accuracy: 0.9999 - val_loss: 6.2653e-09 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7000e-05 - accuracy: 1.0000 - val_loss: 6.1812e-09 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4587e-05 - accuracy: 1.0000 - val_loss: 4.0788e-09 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8209e-05 - accuracy: 1.0000 - val_loss: 2.0604e-09 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8483e-05 - accuracy: 1.0000 - val_loss: 6.1812e-09 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7376e-05 - accuracy: 1.0000 - val_loss: 3.1116e-09 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1680e-05 - accuracy: 1.0000 - val_loss: 2.0184e-09 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.5397e-05 - accuracy: 1.0000 - val_loss: 2.4388e-09 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8081e-05 - accuracy: 1.0000 - val_loss: 1.7240e-09 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.6207e-05 - accuracy: 1.0000 - val_loss: 4.0367e-09 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1893e-05 - accuracy: 1.0000 - val_loss: 1.3456e-09 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1135e-05 - accuracy: 1.0000 - val_loss: 1.8922e-09 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8642e-05 - accuracy: 1.0000 - val_loss: 1.0933e-09 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8972e-05 - accuracy: 1.0000 - val_loss: 7.5688e-10 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.4673e-05 - accuracy: 1.0000 - val_loss: 2.3700e-07 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3490e-04 - accuracy: 0.9999 - val_loss: 1.6399e-09 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.5954e-05 - accuracy: 1.0000 - val_loss: 1.4885e-08 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.3928e-04 - accuracy: 0.9998 - val_loss: 3.0696e-09 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9804e-05 - accuracy: 1.0000 - val_loss: 1.8502e-09 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8673e-04 - accuracy: 0.9999 - val_loss: 7.7370e-09 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6273e-05 - accuracy: 1.0000 - val_loss: 4.1629e-09 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.5028e-05 - accuracy: 1.0000 - val_loss: 2.1445e-09 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.6800e-05 - accuracy: 1.0000 - val_loss: 6.1812e-09 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.9600e-05 - accuracy: 1.0000 - val_loss: 3.9947e-09 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.2151e-05 - accuracy: 1.0000 - val_loss: 2.1025e-09 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.3284e-05 - accuracy: 1.0000 - val_loss: 1.3035e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0430e-04 - accuracy: 0.9999 - val_loss: 3.2378e-09 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2930e-05 - accuracy: 1.0000 - val_loss: 1.0933e-09 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.1441e-05 - accuracy: 1.0000 - val_loss: 6.0130e-09 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1476e-05 - accuracy: 1.0000 - val_loss: 2.4388e-09 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8041e-05 - accuracy: 1.0000 - val_loss: 1.8081e-09 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5490e-05 - accuracy: 1.0000 - val_loss: 1.4297e-09 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.7729e-06 - accuracy: 1.0000 - val_loss: 6.3074e-10 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7938e-05 - accuracy: 1.0000 - val_loss: 1.0933e-09 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.4540e-05 - accuracy: 1.0000 - val_loss: 3.4480e-09 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1626e-05 - accuracy: 1.0000 - val_loss: 2.4809e-09 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.5927e-06 - accuracy: 1.0000 - val_loss: 1.3035e-09 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7782e-04 - accuracy: 0.9999 - val_loss: 3.7003e-09 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7824e-05 - accuracy: 1.0000 - val_loss: 1.0933e-09 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.0426e-05 - accuracy: 1.0000 - val_loss: 2.5650e-09 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.9958e-05 - accuracy: 1.0000 - val_loss: 4.8356e-09 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3309e-05 - accuracy: 1.0000 - val_loss: 1.4297e-09 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6675e-05 - accuracy: 1.0000 - val_loss: 5.8869e-10 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.3811e-05 - accuracy: 1.0000 - val_loss: 7.5688e-10 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4754e-05 - accuracy: 1.0000 - val_loss: 6.7278e-09 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1409e-04 - accuracy: 0.9999 - val_loss: 2.7878e-08 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1178e-05 - accuracy: 1.0000 - val_loss: 2.5229e-09 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0402e-05 - accuracy: 1.0000 - val_loss: 2.2706e-09 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4448e-05 - accuracy: 1.0000 - val_loss: 9.3769e-09 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2495e-05 - accuracy: 1.0000 - val_loss: 1.0092e-09 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0999e-05 - accuracy: 1.0000 - val_loss: 1.7661e-09 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9220e-04 - accuracy: 1.0000 - val_loss: 2.9014e-09 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3960e-04 - accuracy: 0.9999 - val_loss: 1.5979e-09 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.2353e-06 - accuracy: 1.0000 - val_loss: 1.5558e-09 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.0055e-05 - accuracy: 1.0000 - val_loss: 6.7279e-10 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6238e-05 - accuracy: 1.0000 - val_loss: 2.7752e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "11336/11336 [==============================] - 17s 1ms/step - loss: 5.0338e-06 - accuracy: 1.0000 - val_loss: 2.1025e-09 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.0680e-05 - accuracy: 1.0000 - val_loss: 7.9893e-10 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1169e-05 - accuracy: 1.0000 - val_loss: 1.1774e-09 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2626e-05 - accuracy: 1.0000 - val_loss: 7.6108e-09 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4801e-04 - accuracy: 0.9999 - val_loss: 1.2615e-09 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2303e-05 - accuracy: 1.0000 - val_loss: 7.9893e-10 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6296e-05 - accuracy: 1.0000 - val_loss: 1.3035e-09 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0345e-05 - accuracy: 1.0000 - val_loss: 1.4297e-09 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6282e-05 - accuracy: 1.0000 - val_loss: 4.6254e-09 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7343e-05 - accuracy: 1.0000 - val_loss: 7.9893e-10 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8197e-05 - accuracy: 1.0000 - val_loss: 1.8502e-09 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5421e-05 - accuracy: 1.0000 - val_loss: 2.8173e-09 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0622e-05 - accuracy: 1.0000 - val_loss: 2.2286e-09 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5410e-04 - accuracy: 0.9999 - val_loss: 1.1816e-08 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8826e-05 - accuracy: 1.0000 - val_loss: 2.8173e-09 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.7698e-05 - accuracy: 1.0000 - val_loss: 5.4664e-10 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2464e-05 - accuracy: 1.0000 - val_loss: 6.3074e-10 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9587e-04 - accuracy: 0.9999 - val_loss: 3.1537e-09 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7109e-05 - accuracy: 1.0000 - val_loss: 2.9434e-10 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8234e-05 - accuracy: 1.0000 - val_loss: 2.3968e-09 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7612e-05 - accuracy: 1.0000 - val_loss: 1.0933e-09 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.6738e-06 - accuracy: 1.0000 - val_loss: 8.4098e-10 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6551e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.3182e-05 - accuracy: 1.0000 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4538e-05 - accuracy: 1.0000 - val_loss: 5.0459e-10 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1779e-04 - accuracy: 1.0000 - val_loss: 3.5908e-08 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0262e-04 - accuracy: 0.9999 - val_loss: 2.3631e-08 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2487e-05 - accuracy: 1.0000 - val_loss: 2.1445e-09 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6764e-05 - accuracy: 1.0000 - val_loss: 3.3639e-10 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.2157e-06 - accuracy: 1.0000 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.9253e-05 - accuracy: 1.0000 - val_loss: 1.0933e-09 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8726e-05 - accuracy: 1.0000 - val_loss: 1.6861e-08 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4161e-04 - accuracy: 0.9999 - val_loss: 2.9014e-09 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0417e-05 - accuracy: 1.0000 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.9215e-05 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3029e-05 - accuracy: 1.0000 - val_loss: 2.1865e-09 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.2942e-05 - accuracy: 1.0000 - val_loss: 5.4664e-10 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.9414e-05 - accuracy: 1.0000 - val_loss: 1.0722e-08 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.7440e-05 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.7493e-05 - accuracy: 1.0000 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.9712e-05 - accuracy: 1.0000 - val_loss: 8.8303e-10 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0257e-05 - accuracy: 1.0000 - val_loss: 5.0459e-10 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1789e-05 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.9007e-05 - accuracy: 1.0000 - val_loss: 2.9434e-10 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.3988e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.7157e-06 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8321e-04 - accuracy: 0.9999 - val_loss: 5.6346e-09 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1279e-05 - accuracy: 1.0000 - val_loss: 1.1353e-09 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.5079e-06 - accuracy: 1.0000 - val_loss: 5.0459e-10 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9681e-05 - accuracy: 1.0000 - val_loss: 5.8869e-10 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.3079e-05 - accuracy: 1.0000 - val_loss: 1.6820e-09 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6960e-06 - accuracy: 1.0000 - val_loss: 5.8869e-10 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7056e-05 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.5608e-05 - accuracy: 0.9999 - val_loss: 1.1774e-09 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8826e-05 - accuracy: 1.0000 - val_loss: 5.8869e-10 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.9541e-04 - accuracy: 0.9999 - val_loss: 7.5688e-10 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1195e-05 - accuracy: 1.0000 - val_loss: 5.4664e-10 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8442e-05 - accuracy: 1.0000 - val_loss: 9.2508e-10 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.5092e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2816e-05 - accuracy: 1.0000 - val_loss: 4.2049e-10 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.5892e-06 - accuracy: 1.0000 - val_loss: 3.3639e-10 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6082e-05 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4135e-05 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4691e-05 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0072e-05 - accuracy: 1.0000 - val_loss: 3.7844e-10 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2799e-05 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.0428e-06 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4463e-05 - accuracy: 1.0000 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8389e-05 - accuracy: 1.0000 - val_loss: 5.0459e-10 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4419e-05 - accuracy: 1.0000 - val_loss: 9.2508e-10 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.0102e-06 - accuracy: 1.0000 - val_loss: 3.3639e-10 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.5570e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1429e-05 - accuracy: 1.0000 - val_loss: 3.7844e-10 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6229e-05 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.2509e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.2670e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.1678e-05 - accuracy: 0.9999 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1213e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8925e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.0707e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2043e-04 - accuracy: 0.9999 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1909e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2677e-05 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4760e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.9950e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0507e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5009e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.4412e-05 - accuracy: 1.0000 - val_loss: 3.7844e-10 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8763e-05 - accuracy: 1.0000 - val_loss: 3.3639e-10 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7721e-05 - accuracy: 1.0000 - val_loss: 1.2138e-07 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9618e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6744e-04 - accuracy: 0.9999 - val_loss: 1.4212e-08 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.6634e-05 - accuracy: 0.9999 - val_loss: 2.3547e-09 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8202e-05 - accuracy: 1.0000 - val_loss: 2.2286e-09 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2598e-04 - accuracy: 0.9999 - val_loss: 1.4002e-08 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.3605e-05 - accuracy: 1.0000 - val_loss: 2.1361e-08 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6806e-05 - accuracy: 1.0000 - val_loss: 1.4717e-09 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.2221e-05 - accuracy: 1.0000 - val_loss: 1.0092e-09 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6021e-05 - accuracy: 1.0000 - val_loss: 8.6200e-09 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.2438e-05 - accuracy: 1.0000 - val_loss: 1.8502e-09 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4623e-06 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.5919e-05 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.3484e-06 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5621e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7923e-05 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.6645e-05 - accuracy: 1.0000 - val_loss: 3.9106e-09 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.5966e-06 - accuracy: 1.0000 - val_loss: 7.5688e-10 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1012e-05 - accuracy: 1.0000 - val_loss: 4.2049e-10 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4574e-04 - accuracy: 0.9999 - val_loss: 5.4664e-10 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7196e-06 - accuracy: 1.0000 - val_loss: 3.7844e-10 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.5926e-06 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7573e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.5276e-05 - accuracy: 0.9999 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1188e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.9136e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.0929e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.4984e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4438e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2460e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.8388e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.3154e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1306e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.5220e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.5723e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6648e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0553e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.1575e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8332e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5124e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8712e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.6665e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.5230e-04 - accuracy: 0.9999 - val_loss: 2.0604e-09 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.8982e-06 - accuracy: 1.0000 - val_loss: 6.7279e-10 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.8184e-06 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.5113e-06 - accuracy: 1.0000 - val_loss: 1.0092e-09 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6164e-05 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.9697e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7291e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3330e-04 - accuracy: 0.9999 - val_loss: 3.7844e-10 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3361e-05 - accuracy: 1.0000 - val_loss: 3.3639e-10 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.2793e-05 - accuracy: 1.0000 - val_loss: 4.2049e-10 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.4107e-05 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8509e-04 - accuracy: 0.9999 - val_loss: 5.0459e-10 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0409e-05 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6947e-05 - accuracy: 1.0000 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.3659e-05 - accuracy: 1.0000 - val_loss: 3.3639e-10 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4872e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.1839e-05 - accuracy: 1.0000 - val_loss: 3.9526e-09 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.3187e-05 - accuracy: 1.0000 - val_loss: 3.6162e-09 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.8410e-05 - accuracy: 1.0000 - val_loss: 8.9984e-09 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.3060e-06 - accuracy: 1.0000 - val_loss: 7.9893e-09 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.7656e-06 - accuracy: 1.0000 - val_loss: 1.4717e-09 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3277e-05 - accuracy: 1.0000 - val_loss: 7.1483e-10 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1326e-05 - accuracy: 1.0000 - val_loss: 5.4664e-10 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.1191e-05 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1955e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.7058e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6992e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7775e-05 - accuracy: 1.0000 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1293e-05 - accuracy: 1.0000 - val_loss: 1.1774e-09 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.4483e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.9336e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3256e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.5534e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8286e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4648e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.2418e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5452e-05 - accuracy: 1.0000 - val_loss: 2.9434e-10 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.0880e-05 - accuracy: 0.9999 - val_loss: 8.4098e-10 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2492e-05 - accuracy: 1.0000 - val_loss: 4.2049e-10 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3534e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.9881e-06 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9235e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.2434e-05 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.2003e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0646e-05 - accuracy: 1.0000 - val_loss: 3.7844e-10 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.2653e-06 - accuracy: 1.0000 - val_loss: 3.7844e-10 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.9741e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7877e-05 - accuracy: 1.0000 - val_loss: 2.9434e-10 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.9352e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0506e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1644e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.8052e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.4262e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8352e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2575e-05 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.5842e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.9892e-06 - accuracy: 1.0000 - val_loss: 1.4297e-09 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.8593e-06 - accuracy: 1.0000 - val_loss: 1.2194e-09 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.0989e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.6490e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0020e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8122e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1926e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1378e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.6076e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.5997e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3222e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.7289e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.3057e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6048e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.4814e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8048e-05 - accuracy: 1.0000 - val_loss: 1.0512e-09 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.7515e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9591e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.9724e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2656e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.7692e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.6244e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.9133e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.3715e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.4839e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6304e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.6708e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0824e-04 - accuracy: 0.9999 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.3296e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.3922e-05 - accuracy: 1.0000 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.8308e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.3045e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2865e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2454e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2415e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4541e-04 - accuracy: 0.9999 - val_loss: 7.7790e-09 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1934e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.3327e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.7136e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.5636e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.8706e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1742e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.4400e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0509e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.8046e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.8407e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7392e-05 - accuracy: 1.0000 - val_loss: 3.7424e-09 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.2547e-06 - accuracy: 1.0000 - val_loss: 5.4243e-09 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1841e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.2938e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.5004e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.6226e-06 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.9388e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.0134e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.4205e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.3063e-05 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.3101e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6721e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.4660e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.8045e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.0256e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7993e-04 - accuracy: 0.9999 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.5947e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6115e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.1887e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6321e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1924e-05 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.6562e-04 - accuracy: 0.9999 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.9887e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.5064e-06 - accuracy: 1.0000 - val_loss: 3.3639e-10 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.1791e-06 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4141e-05 - accuracy: 1.0000 - val_loss: 4.7095e-09 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.1210e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3082e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0835e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.8026e-05 - accuracy: 0.9999 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.3309e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.6731e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.6916e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.5427e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.3122e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.2576e-06 - accuracy: 1.0000 - val_loss: 2.1025e-10 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.1309e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.0374e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.1695e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.4430e-06 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.2438e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.4873e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.0777e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.4621e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.2438e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1334e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 9.3169e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.5022e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4664e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.1451e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 6.6961e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.0815e-04 - accuracy: 0.9999 - val_loss: 4.6254e-10 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.6052e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.7769e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1016e-04 - accuracy: 0.9999 - val_loss: 2.5229e-10 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 3.3073e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 8.3557e-06 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.7420e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.2692e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.2314e-05 - accuracy: 1.0000 - val_loss: 1.2615e-10 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.1237e-04 - accuracy: 0.9999 - val_loss: 5.5504e-09 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 1.5470e-04 - accuracy: 0.9999 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 4.3793e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.9326e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.4743e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 7.3259e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 2.7437e-05 - accuracy: 1.0000 - val_loss: 4.2049e-11 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.6889e-06 - accuracy: 1.0000 - val_loss: 8.4098e-11 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "11336/11336 [==============================] - 16s 1ms/step - loss: 5.3236e-05 - accuracy: 1.0000 - val_loss: 1.6820e-10 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe46f3a7b10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the NN\n",
    "batch_size = 120\n",
    "epochs = 500\n",
    "\n",
    "model2.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to models directory.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# serialize model to JSON\n",
    "model_json = model2.to_json()\n",
    "with open(\"../output/models/sequential_500epochs.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model2.save_weights(\"../output/models/sequential_500epochs.h5\")\n",
    "print(\"Saved model to models directory.\")'''\n",
    "\n",
    "# Guardar arquitectura + pesos en un solo archivo HDF5\n",
    "\n",
    "model2.save(\"../output/models/sequential_500epochs.json\")\n",
    "model.save(\"../output/models/sequential_30epochs.json\")\n",
    "print(\"Saved model to models directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict y predict_proba me devuelve el mismo array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_vector)\n",
    "#print(\"Accuracy score: \", accuracy_score(y_test, y_pred, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.argmax(y_pred, axis=1)\n",
    "reality = np.argmax(y_test_vector, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \", accuracy_score(reality, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[865]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5954979e-13, 1.6716356e-13, 1.0000000e+00, 9.3996338e-12,\n",
       "       4.4506796e-16, 3.8997217e-14, 7.6325139e-15], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[865]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy de 1... Demasiado locura.\n",
    "#### Pruebo modelo con muestra fuera del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resizeimage import resizeimage\n",
    "\n",
    "def tryImage(path):\n",
    "    with open(path, 'r+b') as f:\n",
    "        with Image.open(f) as image:\n",
    "            cover = resizeimage.resize_cover(image, [28, 28])\n",
    "            img = cover.convert('L')\n",
    "            arr = np.array(img).flatten().reshape((1,28,28,1))\n",
    "            return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe4825edb50>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 28, 28, 1) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-75671dfcc88e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprueba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtryImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pruebas/prueba3.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprueba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2677\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 28, 28, 1) for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAMbElEQVR4nO3bcYikd33H8ffHXFNpGrWYFeTuNJFeGq+2kHRJU4SaYlouKdz9YZE7CG1KyKE1UlAKKZZU4l9WakG41l6pRAWNp3+UBU8CtZGAeDEbEmPuQmQ9bXNRmjOm/iMaQ7/9YybtZL+7mSd3szO39f2ChXme+e3Md4fhfc8881yqCkma9IpFDyDpwmMYJDWGQVJjGCQ1hkFSYxgkNVPDkOQTSZ5O8tgm9yfJx5KsJXk0yTWzH1PSPA05Yrgb2PcS998I7Bn/HAb+4fzHkrRIU8NQVfcDP3yJJQeAT9XICeA1SV4/qwElzd+OGTzGTuDJie0z433fX78wyWFGRxVccsklv3XVVVfN4Oklbeahhx76QVUtvdzfm0UYBquqo8BRgOXl5VpdXZ3n00s/d5L8+7n83iy+lXgK2D2xvWu8T9I2NYswrAB/PP524jrgR1XVPkZI2j6mfpRI8lngeuCyJGeAvwZ+AaCqPg4cB24C1oAfA3+6VcNKmo+pYaiqQ1PuL+A9M5tI0sJ55aOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6RmUBiS7EvyRJK1JHdscP8bktyX5OEkjya5afajSpqXqWFIchFwBLgR2AscSrJ33bK/Ao5V1dXAQeDvZz2opPkZcsRwLbBWVaer6jngHuDAujUFvGp8+9XA92Y3oqR5GxKGncCTE9tnxvsmfRC4OckZ4Djw3o0eKMnhJKtJVs+ePXsO40qah1mdfDwE3F1Vu4CbgE8naY9dVUerarmqlpeWlmb01JJmbUgYngJ2T2zvGu+bdCtwDKCqvga8ErhsFgNKmr8hYXgQ2JPkiiQXMzq5uLJuzX8AbwdI8mZGYfCzgrRNTQ1DVT0P3A7cCzzO6NuHk0nuSrJ/vOz9wG1JvgF8Frilqmqrhpa0tXYMWVRVxxmdVJzcd+fE7VPAW2c7mqRF8cpHSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUDApDkn1JnkiyluSOTda8M8mpJCeTfGa2Y0qapx3TFiS5CDgC/D5wBngwyUpVnZpYswf4S+CtVfVsktdt1cCStt6QI4ZrgbWqOl1VzwH3AAfWrbkNOFJVzwJU1dOzHVPSPA0Jw07gyYntM+N9k64Erkzy1SQnkuzb6IGSHE6ymmT17Nmz5zaxpC03q5OPO4A9wPXAIeCfkrxm/aKqOlpVy1W1vLS0NKOnljRrQ8LwFLB7YnvXeN+kM8BKVf2sqr4DfItRKCRtQ0PC8CCwJ8kVSS4GDgIr69b8C6OjBZJcxuijxekZzilpjqaGoaqeB24H7gUeB45V1ckkdyXZP152L/BMklPAfcBfVNUzWzW0pK2VqlrIEy8vL9fq6upCnlv6eZHkoapafrm/55WPkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLIvyRNJ1pLc8RLr3pGkkizPbkRJ8zY1DEkuAo4ANwJ7gUNJ9m6w7lLgz4EHZj2kpPkacsRwLbBWVaer6jngHuDABus+BHwY+MkM55O0AEPCsBN4cmL7zHjf/0pyDbC7qr74Ug+U5HCS1SSrZ8+efdnDSpqP8z75mOQVwEeB909bW1VHq2q5qpaXlpbO96klbZEhYXgK2D2xvWu87wWXAm8BvpLku8B1wIonIKXta0gYHgT2JLkiycXAQWDlhTur6kdVdVlVXV5VlwMngP1VtbolE0vaclPDUFXPA7cD9wKPA8eq6mSSu5Ls3+oBJc3fjiGLquo4cHzdvjs3WXv9+Y8laZG88lFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWDwpBkX5InkqwluWOD+9+X5FSSR5N8OckbZz+qpHmZGoYkFwFHgBuBvcChJHvXLXsYWK6q3wS+APzNrAeVND9DjhiuBdaq6nRVPQfcAxyYXFBV91XVj8ebJ4Bdsx1T0jwNCcNO4MmJ7TPjfZu5FfjSRnckOZxkNcnq2bNnh08paa5mevIxyc3AMvCRje6vqqNVtVxVy0tLS7N8akkztGPAmqeA3RPbu8b7XiTJDcAHgLdV1U9nM56kRRhyxPAgsCfJFUkuBg4CK5MLklwN/COwv6qenv2YkuZpahiq6nngduBe4HHgWFWdTHJXkv3jZR8Bfhn4fJJHkqxs8nCStoEhHyWoquPA8XX77py4fcOM55K0QF75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyRZC3JHRvc/4tJPje+/4Ekl896UEnzMzUMSS4CjgA3AnuBQ0n2rlt2K/BsVf0q8HfAh2c9qKT5GXLEcC2wVlWnq+o54B7gwLo1B4BPjm9/AXh7ksxuTEnztGPAmp3AkxPbZ4Df3mxNVT2f5EfAa4EfTC5Kchg4PN78aZLHzmXoBbmMdX/PBWw7zQrba97tNCvAr53LLw0Jw8xU1VHgKECS1apanufzn4/tNO92mhW217zbaVYYzXsuvzfko8RTwO6J7V3jfRuuSbIDeDXwzLkMJGnxhoThQWBPkiuSXAwcBFbWrVkB/mR8+4+Af6uqmt2YkuZp6keJ8TmD24F7gYuAT1TVySR3AatVtQL8M/DpJGvADxnFY5qj5zH3ImynebfTrLC95t1Os8I5zhv/YZe0nlc+SmoMg6Rmy8OwnS6nHjDr+5KcSvJoki8neeMi5pyY5yXnnVj3jiSVZGFfsw2ZNck7x6/vySSfmfeM62aZ9l54Q5L7kjw8fj/ctIg5x7N8IsnTm10XlJGPjf+WR5NcM/VBq2rLfhidrPw28CbgYuAbwN51a/4M+Pj49kHgc1s503nO+nvAL41vv3tRsw6dd7zuUuB+4ASwfKHOCuwBHgZ+Zbz9ugv5tWV0Uu/d49t7ge8ucN7fBa4BHtvk/puALwEBrgMemPaYW33EsJ0up546a1XdV1U/Hm+eYHRNx6IMeW0BPsTo/678ZJ7DrTNk1tuAI1X1LEBVPT3nGScNmbeAV41vvxr43hzne/EgVfcz+jZwMweAT9XICeA1SV7/Uo+51WHY6HLqnZutqarngRcup563IbNOupVRhRdl6rzjQ8bdVfXFeQ62gSGv7ZXAlUm+muREkn1zm64bMu8HgZuTnAGOA++dz2jn5OW+t+d7SfT/F0luBpaBty16ls0keQXwUeCWBY8y1A5GHyeuZ3Qkdn+S36iq/1roVJs7BNxdVX+b5HcYXcfzlqr670UPNgtbfcSwnS6nHjIrSW4APgDsr6qfzmm2jUyb91LgLcBXknyX0WfLlQWdgBzy2p4BVqrqZ1X1HeBbjEKxCEPmvRU4BlBVXwNeyeg/WF2IBr23X2SLT4rsAE4DV/B/J3F+fd2a9/Dik4/HFnQCZ8isVzM6KbVnETO+3HnXrf8Kizv5OOS13Qd8cnz7MkaHvq+9gOf9EnDL+PabGZ1jyALfD5ez+cnHP+TFJx+/PvXx5jDwTYzq/23gA+N9dzH6FxdGpf08sAZ8HXjTAl/cabP+K/CfwCPjn5VFzTpk3nVrFxaGga9tGH30OQV8Ezh4Ib+2jL6J+Oo4Go8Af7DAWT8LfB/4GaMjr1uBdwHvmnhtj4z/lm8OeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prueba = tryImage('pruebas/prueba3.jpeg')\n",
    "plt.imshow(prueba, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "      <th>V</th>\n",
       "      <th>Y</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12540</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8817</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2835 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A  B  F  T  V  Y  other\n",
       "3448   0  0  0  1  0  0      0\n",
       "13025  0  0  1  0  0  0      0\n",
       "9002   0  0  0  0  0  0      1\n",
       "12540  1  0  0  0  0  0      0\n",
       "10298  0  0  0  0  0  0      1\n",
       "...   .. .. .. .. .. ..    ...\n",
       "4058   0  0  0  1  0  0      0\n",
       "85     1  0  0  0  0  0      0\n",
       "4442   0  0  0  1  0  0      0\n",
       "1219   0  1  0  0  0  0      0\n",
       "8817   0  0  0  0  0  0      1\n",
       "\n",
       "[2835 rows x 7 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
